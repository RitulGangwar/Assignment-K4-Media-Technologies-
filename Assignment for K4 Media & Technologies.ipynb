{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85df5076-82b0-4248-bfae-b3987b26fd37",
   "metadata": {},
   "source": [
    "# Q: Can Artificial Intelligence (AI) play games (like HTML5 Games similar to this - https://k4.games/)? If yes, how can you use concepts of computer vision to prove this and tool you need to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10365d8-f4fc-417e-bf00-ae7acaabd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://k4.games/\")\n",
    "\n",
    "# Function to capture game screenshot and identify player position\n",
    "def get_screenshot_and_player(image):\n",
    "  # Process the image (replace with specific detection logic)\n",
    "  # Here's a basic example assuming the player is a red circle\n",
    "  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "  lower_red = np.array([160, 100, 100])\n",
    "  upper_red = np.array([180, 255, 255])\n",
    "  mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "  contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  player_center = None\n",
    "  # Find the largest contour (assuming it's the player)\n",
    "  if len(contours) > 0:\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    ((x, y), radius) = cv2.minEnclosingCircle(largest_contour)\n",
    "    player_center = (int(x), int(y))\n",
    "  return image, player_center\n",
    "\n",
    "# Custom Gym environment\n",
    "class GameEnv(gym.Env):\n",
    "  def __init__(self):\n",
    "    super(GameEnv, self).__init__()\n",
    "    # Define action and observation space\n",
    "    self.action_space = gym.spaces.Discrete(2)  # Example: 2 actions (left, right)\n",
    "    self.observation_space = gym.spaces.Box(low=0, high=255, shape=(height, width, 3), dtype=np.uint8)\n",
    "    # Initial values (update during reset)\n",
    "    self.height = None\n",
    "    self.width = None\n",
    "    self.player_center = None\n",
    "\n",
    "  def reset(self):\n",
    "    driver.refresh()\n",
    "    # Consider waiting for specific game element to reload\n",
    "    # ...\n",
    "    screenshot, self.player_center = get_screenshot_and_player(driver.get_screenshot_as_png())\n",
    "    self.height, self.width = screenshot.shape[:2]\n",
    "    self.observation_space = gym.spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)\n",
    "    return screenshot\n",
    "\n",
    "  def step(self, action):\n",
    "    # Explore alternative element selection for key presses\n",
    "    # ...\n",
    "    if action == 0:\n",
    "      driver.find_element(By.CSS_SELECTOR, \"body\").send_keys(Keys.ARROW_LEFT)\n",
    "    else:\n",
    "      driver.find_element(By.CSS_SELECTOR, \"body\").send_keys(Keys.ARROW_RIGHT)\n",
    "\n",
    "    time.sleep(0.1)  # Temporary sleep for demonstration\n",
    "\n",
    "    obs, _ = get_screenshot_and_player(driver.get_screenshot_as_png())\n",
    "    # Calculate reward based on game state (e.g., distance moved closer to goal)\n",
    "    reward = 0  # Implement reward logic (consider player movement)\n",
    "    # Determine done condition based on game termination (game over screen)\n",
    "    done = False  # Implement done logic\n",
    "\n",
    "    # Check if player moved closer or further from potential goal (replace with actual goal detection)\n",
    "    if self.player_center is not None and obs is not None:\n",
    "      new_player_center, _ = get_screenshot_and_player(obs)\n",
    "      if new_player_center is not None:\n",
    "        distance_before = cv2.norm(self.player_center)\n",
    "        distance_after = cv2.norm(new_player_center)\n",
    "        reward = distance_before - distance_after\n",
    "\n",
    "    self.player_center = new_player_center\n",
    "    return obs, reward, done, {}\n",
    "\n",
    "# Create and train the model (assuming height and width are obtained)\n",
    "env = GameEnv()\n",
    "model = PPO('CnnPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Play the game with the trained mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6c2e6-1515-4e74-81f3-489459e0eb0d",
   "metadata": {},
   "source": [
    "# Q: Is AI animation is possible? If yes, what kind of AI/ML tools can be used for making videos (like https://www.youtube.com/watch?v=ajKIsf4ncu0 ). Also, let us know how can we develop some basic tools for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582b6bb-2ecf-4ca7-83c0-b714edb5d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the generator\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=100, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(784, activation='sigmoid'))\n",
    "    model.add(layers.Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "# Create the discriminator\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Compile the GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "    gan_input = layers.Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = tf.keras.models.Model(gan_input, gan_output)\n",
    "    gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return gan\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "# Training the GAN\n",
    "def train_gan(gan, generator, discriminator, epochs=10000, batch_size=128):\n",
    "    (X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
    "            save_images(generator, epoch)\n",
    "\n",
    "def save_images(generator, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, (examples, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    fig, axs = plt.subplots(dim[0], dim[1], figsize=figsize)\n",
    "    count = 0\n",
    "    for i in range(dim[0]):\n",
    "        for j in range(dim[1]):\n",
    "            axs[i, j].imshow(generated_images[count, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            count += 1\n",
    "    plt.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "train_gan(gan, generator, discriminator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
